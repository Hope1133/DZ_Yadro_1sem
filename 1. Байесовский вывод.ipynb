{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDjH5VgLMPCa"
   },
   "source": [
    "# Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8T7M9eQMRRn"
   },
   "source": [
    "Пусть $X_1, X_2, \\ldots, X_n$ — выборка из экспоненциального распределения с параметром $\\lambda$. Найти оценку максимального правдоподобия параметра $\\lambda$, сравнить ее с байесовской оценкой (MAP и математическое ожидание апостреорного распределения), подобрав сопряженное распределение. Сравнить полученные байесовские оценки с оценкой MLE. Найти предсказательное распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Экспоненциальное распределение с параметром $\\lambda$:  \n",
    "$$\n",
    "f_\\xi(x) = \\begin{cases}\n",
    " 0, & x < 0 \\\\\n",
    " \\lambda e^{-\\lambda x}, & x \\geq 0\n",
    " \\end{cases}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Найдем оценку максимального правдоподобия параметра $\\lambda$:  \n",
    "Правдоподобие - вероятность получения выборки D при параметре $\\lambda$:\n",
    "$$Likelihood(D, \\lambda) = \\mathsf{P}(D|\\lambda) = \\mathsf{P}(x_1, ..., x_n|\\lambda) = \\prod\\limits_{i=1}^{n}f(x_i|\\lambda) = (\\lambda^n e^{-\\lambda \\sum \\limits_{i=1}^n x_i})$$\n",
    "\n",
    "Произведение сильно чувствительно к множителям близким к 0, поэтому перейдем к сумме с помощью логарифма:\n",
    "\n",
    "$$\\ell = \\ln(Likelihood(D, \\lambda)) = \\ln(\\lambda^n e^{-\\lambda \\sum \\limits_{i=1}^n x_i}) = \\ln (\\lambda^n) - \\lambda \\sum \\limits_{i=1}^n x_i = [\\overline{X} = \\frac{1}{n} \\sum \\limits_{i=1}^n x_i] = n \\ln \\lambda - \\lambda n\\overline{X}$$\n",
    "\n",
    "Находим максимальное правдоподобие, через максимум логарифмического правдоподобия:\n",
    "\n",
    "$$\\frac{d\\ell}{d\\lambda} = ( n \\ln \\lambda - \\lambda n\\overline{X})_\\lambda^{'}= \\frac{n}{\\lambda} - n\\overline{X}=0$$\n",
    "$$⇒ \\hat{\\lambda}_{MLE}=\\frac{1}{\\overline{X}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Баесовская оценка (MAP и математическое ожидание апостреорного распределения)\n",
    "\n",
    "**Байесовский подход:** рассматриваем параметр $\\lambda$ как случайную величину с априорным распределением $p(\\lambda)$.\n",
    "\n",
    "Теорема Байеса:\n",
    "$$\n",
    "p(\\lambda|D) = \\frac{p(D|\\lambda)p(\\lambda)}{p(D)} \\propto p(D|\\lambda)p(\\lambda)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Сопряженное априорное распределение — такое априорное распределение, при котором апостериорное распределение принадлежит тому же семейству, что и априорное (Это упрощает вычисления)\n",
    "\n",
    "В качестве сопряженного распределения к правдоподобию используем гамма-распределение $\\lambda ∼\\Gamma(a,b)$ :\n",
    "\n",
    "$$\n",
    "p(\\lambda|a,b) = \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} e^{-b\\lambda}, \\quad \\lambda > 0\n",
    "$$\n",
    "$$\\mathsf{E}(\\lambda) = \\frac{a}{b} \\quad\\quad mode = \\frac{a-1}{b}$$\n",
    "\n",
    "\n",
    "Таким образом, априорная вероятность: $\\mathsf P(\\lambda) = \\frac{b^a}{\\Gamma (a)}\\lambda^{a-1}e^{-b\\lambda}$   \n",
    "Функция правдоподобия:$\\mathsf P(D|\\lambda) = \\lambda^{n}e^{-n\\lambda\\overline{X}}$   \n",
    "\n",
    "Тогда апостериорное распределение:\n",
    "$$\n",
    "p(\\lambda|D) \\propto p(D|\\lambda)p(\\lambda) \\propto \\left[\\lambda^n e^{-\\lambda n\\overline{X}}\\right] \\cdot \\left[\\lambda^{a-1} e^{-b\\lambda}\\right] = \\lambda^{n+a-1} e^{-\\lambda(b + n\\overline{X})} \\propto \\Gamma(a+n, b+n\\overline{X})\n",
    "$$\n",
    "\n",
    "Тогда математическое ожидание апостериорного распределения и MAP оценка(мода апостериорного распределения) находим по формулам для гамма-распределения:\n",
    "$$\n",
    "\\hat{\\lambda}_b = \\frac{n+a}{b+n\\overline{X}}\n",
    "$$\n",
    "$$\n",
    "\\hat{\\lambda}_{MAP} = \\frac{n+a-1}{b+n\\overline{X}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение с MLE\n",
    "\n",
    "$$ \\hat{\\lambda}_{MLE}=\\frac{1}{\\overline{X}} $$\n",
    "$$ \\hat{\\lambda}_{MAP} = \\frac{n+a-1}{b+n\\overline{X}} $$\n",
    "$$\\hat{\\lambda}_b = \\frac{n+a}{b+n\\overline{X}}$$\n",
    "\n",
    "Чем больше влияние априорного знания (например, большие a, b), тем сильнее различие с MLE, т.к. MLE зависит только от данных ($X$), не использует априорную информацию.  \n",
    "При больших объемах выборки $(n → ∞)$ обе байесовские оценки стремятся к оценке MLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказательное распределение\n",
    "\n",
    "$$\n",
    "\\mathsf{P}(x|D) = \\int\\limits_\\lambda P(x|\\lambda)P(λ|D)d\\lambda = \\int\\limits_0^∞ \\lambda e^{-\\lambda x_i}\\cdot \\frac{(b+n\\overline{X})^{a+n}}{\\Gamma(n+a)}\\lambda ^{a+n-1}e^{-\\lambda(b+n\\overline{X})}dλ=\\frac{(b+n\\overline{X})^{a+n}}{\\Gamma(n+a)}\\int\\limits_0^∞ \\lambda^{a+n} e^{-\\lambda(x_i+b+n\\overline{X})}=$$\n",
    "$$=\\frac{(b+n\\overline{X})^{a+n}}{\\Gamma(n+a)}\\cdot \\frac{\\Gamma(a+n+1)}{(x_i+b+n\\overline{X})^{a+n+1}}=\\frac{(a+n)(b+n\\overline{X})^{a+n}}{(x_i+b+n\\overline{X})^{a+n+1}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WBXJuchMhzE"
   },
   "source": [
    "# Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYWArd6bMjkD"
   },
   "source": [
    "**Мультиномиальное распределение**\n",
    "\n",
    "Пусть проводится серия из $n$ испытаний и в результате каждого испытания происходит ровно одно событие из набора $A_1, A_2, \\dots, A_m$, причем вероятности этих событий равны соответственно $\\mathsf{p}_1, \\mathsf{p}_2, \\dots, \\mathsf{p}_m$, причем\n",
    "$$\\sum_{i=1}^{m}\\mathsf{p}_i = 1.$$\n",
    "\n",
    "Тогда совместное распределение величин $X_1, X_2, \\dots, X_m$, где $X_k$ — число наступлений события $A_k$ в серии из $n$ испытаний, задается вероятностями\n",
    "\n",
    "$$\n",
    "\\mathsf{P}\\left(X_1 = n_1, \\dots, X_m = n_m, \\right) = \\frac{n!}{n_1!\\dots n_m!}\\mathsf{p}_1^{n_1}\\dots \\mathsf{p}_m^{n_m},\n",
    "$$\n",
    "\n",
    "где $n_1, n_2, \\dots, n_m$ — произвольный набор целых неотрицательных чисел, таких что\n",
    "\n",
    "$$\\sum_{i=1}^m n_i = n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOvNMoSHMrWR"
   },
   "source": [
    "Произведите байесовский вывод для мультиномиального распределения: найдите апостериорное распределение, используя в качестве сопоряженного распределения к правдоподобию [распределение Дирихле](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%94%D0%B8%D1%80%D0%B8%D1%85%D0%BB%D0%B5), найдите предсказательное распределение. Объясните результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Апесториорное распределение\n",
    "\n",
    "Правдоподобие:\n",
    "$$Likelihood(D, p_1...p_m) = \\mathsf{P}(D|p_1...p_m) = \\frac{n!}{n_1!...n_m!}\\prod\\limits_{i=1}^{m}p_i^{n_i}$$\n",
    "\n",
    "В качестве сопрежяенного распределения к правдоподобию используем распределение Дирихле $p=(p_1...p_m)∼Dir(\\alpha_1...\\alpha_m)$:\n",
    "\n",
    "$$Ep_i = \\frac{\\alpha_i}{\\sum\\limits_i^m \\alpha_i}.$$\n",
    "\n",
    "Тогда априорная вероятность\n",
    "$$\\mathsf{P}(p) = \\frac{1}{B(\\alpha)}\\prod_{i=1}^{m}p_i^{\\alpha_i-1}$$\n",
    "\n",
    "Апестериорное распределение:\n",
    "$$\\mathsf P(p|D) \\propto \\mathsf P(p)\\mathsf P(D|p) \\propto \\prod\\limits_{i=1}^{m}p_i^{n_i} \\prod_{i=1}^{m}p_i^{\\alpha_i-1}  \\propto \\prod_{i=1}^{m} p_i^{n_i+a_i-1}$$\n",
    "\n",
    "Апестериорное распределение остается распределением Дирихле с обновленными параметрами $Dir(\\alpha_1+n_1, ...,\\alpha_m+n_m)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказательное распределение\n",
    "\n",
    "Для одного нового испытания вероятность того, что следующее наблюдение будет типа k:\n",
    "\n",
    "$$\n",
    "P(k|D) = \\int P(k|\\mathbf{p})p(\\mathbf{p}|D)d\\mathbf{p} = \\int p_k p(\\mathbf{p}|D)d\\mathbf{p} = \\mathbb{E}[p_k|D] = \\frac{\\alpha_k + n_k}{\\sum_{i=1}^m (\\alpha_i + n_i)}\n",
    "$$\n",
    "\n",
    "Для $n'$ новых испытаний вероятность наблюдать $n_1', ..., n_m'$ в следующих $n'$ испытаниях:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{n}'|D) = \\int P(\\mathbf{n}'|\\mathbf{p})p(\\mathbf{p}|D)d\\mathbf{p} = \\frac{n'!}{n_1'! \\cdots n_m'!} \\int \\prod_{i=1}^m p_i^{n_i'} \\cdot \\frac{1}{B(\\alpha+\\mathbf{n})} \\prod_{i=1}^m p_i^{\\alpha_i+n_i-1} d\\mathbf{p} = \\frac{n'!}{n_1'! \\cdots n_m'!} \\cdot \\frac{1}{B(\\alpha+\\mathbf{n})} \\int \\prod_{i=1}^m p_i^{n_i'+\\alpha_i+n_i-1} d\\mathbf{p}\n",
    "$$\n",
    "\n",
    "Интеграл равен $B(\\alpha+\\mathbf{n}+\\mathbf{n}')$, поэтому:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{n}'|D) = \\frac{n'!}{n_1'! \\cdots n_m'!} \\cdot \\frac{B(\\alpha+\\mathbf{n}+\\mathbf{n}')}{B(\\alpha+\\mathbf{n})}\n",
    "$$\n",
    "\n",
    "Это полиномиальное бета-распределение (мультиномиальное распределение Дирихле).\n",
    "Параметры распределения Дирихле, которое является сопряженным, можно интерпретировать как \"псевдо-количество событий\". Мы предполагаем, что $k-$событие встречалось $\\alpha_k-1$ раз. Предсказательное распределение, учитывает как априорные знания, так и эмпирически полученные данные."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
